import { QnA } from "../../types";

const webQuestions: QnA[] = [
  {
    question: "브라우저 렌더링 과정을 상세히 설명해주세요.",
    answer:
      "브라우저 렌더링 과정은 다음과 같은 단계로 이루어집니다. 먼저 HTML을 파싱하여 DOM 트리를 생성하고, CSS를 파싱하여 CSSOM 트리를 생성합니다. 이 두 트리를 결합하여 렌더 트리를 만드는데, 이 과정에서 display: none과 같은 비시각적 요소는 제외됩니다. 다음으로 레이아웃(리플로우) 단계에서 각 요소의 크기와 위치를 계산하고, 페인팅 단계에서 실제 픽셀로 화면에 그립니다. 마지막으로 컴포지팅 단계에서 레이어를 합성하여 최종 화면을 생성합니다. 이 과정에서 JavaScript는 DOM과 CSSOM을 수정할 수 있으며, 이는 리플로우나 리페인트를 발생시킬 수 있습니다. 성능 최적화를 위해서는 리플로우와 리페인트를 최소화하고, transform이나 opacity 같은 컴포지터 전용 속성을 활용하는 것이 중요합니다.",
  },
  {
    question:
      "브라우저의 리플로우(Reflow)와 리페인트(Repaint)에 대해 설명하고, 이를 최적화하는 방법을 설명해주세요.",
    answer:
      "리플로우와 리페인트는 브라우저의 렌더링 과정에서 발생하는 중요한 연산입니다. 리플로우는 요소의 크기나 위치가 변경될 때 발생하는 연산으로, 레이아웃 단계에서 모든 요소의 위치와 크기를 다시 계산합니다. DOM 요소의 추가/삭제, 요소의 크기/위치 변경, 윈도우 리사이징, 폰트 변경, width/height/margin 등의 스타일 계산 값 변경시 발생합니다. 리페인트는 요소의 시각적 속성이 변경될 때 발생하는 연산으로, 실제 화면에 픽셀을 그리는 과정입니다. 색상, 배경 이미지, 투명도, outline 등의 변경시 발생합니다. 이러한 연산을 최적화하기 위해서는 여러 가지 방법을 사용할 수 있습니다. CSS 측면에서는 transform, opacity와 같은 GPU 가속 속성을 활용하고, position: fixed/absolute를 사용하여 다른 요소에 대한 레이아웃 영향을 최소화하며, CSS 클래스 변경을 일괄 처리하는 것이 좋습니다. JavaScript 측면에서는 DocumentFragment를 활용하여 DOM 조작을 일괄 처리하고, 요소의 크기나 위치를 읽는 작업과 쓰는 작업을 분리하여 강제 리플로우를 방지합니다. 또한 애니메이션이 필요한 경우 position: fixed나 transform을 사용하여 다른 요소에 영향을 주지 않도록 하고, requestAnimationFrame을 사용하여 렌더링 성능을 최적화할 수 있습니다. 복잡한 레이아웃 변경이 필요한 경우에는 변경 대상 요소를 숨기고(display: none) 변경 후 다시 표시하는 방법도 고려할 수 있습니다.",
  },
  {
    question:
      "주소창에 www.google.com을 입력하면 화면이 표시되기까지 어떤 과정이 일어나나요?",
    answer:
      "전체 과정은 크게 DNS 조회, TCP 연결, HTTP 통신, 브라우저 렌더링 단계로 나눌 수 있습니다. 먼저 DNS 조회 과정에서 브라우저는 자체 DNS 캐시, OS의 DNS 캐시, hosts 파일을 순차적으로 확인하고, 없다면 DNS 서버에 쿼리하여 도메인의 IP 주소를 얻습니다. 다음으로 얻은 IP 주소로 3-way handshake를 통해 TCP 연결을 수립하며, HTTPS의 경우 추가로 TLS handshake가 수행됩니다. 연결이 수립되면 서버에 HTTP GET 요청을 보내고 서버는 HTML 문서를 응답합니다. 브라우저는 받은 HTML을 파싱하여 DOM 트리를 생성하고, CSS를 파싱하여 CSSOM 트리를 생성합니다. 이 과정에서 JavaScript가 실행될 수 있으며, DOM과 CSSOM을 결합하여 렌더 트리를 생성합니다. 마지막으로 레이아웃을 계산하고 페인팅을 수행하여 화면에 표시하며, 이미지나 폰트 등의 추가 리소스들은 필요에 따라 별도로 요청하여 로드됩니다.",
  },
  {
    question:
      "브라우저 저장소(Local Storage, Session Storage, Cookie)의 차이점을 설명해주세요.",
    answer:
      "브라우저 저장소는 각각 다른 특징과 용도를 가지고 있습니다. Local Storage는 영구적인 클라이언트 측 저장소로, 브라우저를 닫아도 데이터가 유지되며 도메인별로 약 5MB까지 저장할 수 있습니다. Session Storage는 세션 기반 저장소로, 탭이나 브라우저를 닫으면 데이터가 삭제되며, 같은 도메인이라도 다른 탭에서는 접근할 수 없습니다. Cookie는 서버와 클라이언트 간의 지속적인 데이터 교환을 위해 사용되며, 만료 기간을 설정할 수 있고 약 4KB까지 저장할 수 있습니다. 쿠키는 매 HTTP 요청에 자동으로 포함되어 서버로 전송되며, HttpOnly, Secure, SameSite 등의 보안 옵션을 설정할 수 있습니다. 용도에 따라 인증 정보는 쿠키, UI 상태는 Local Storage, 임시 데이터는 Session Storage를 사용하는 것이 일반적입니다.",
  },
  {
    question: "브라우저의 Same Origin Policy와 CORS에 대해 설명해주세요.",
    answer:
      "Same Origin Policy는 웹 보안의 핵심 정책으로, 동일 출처(프로토콜, 호스트, 포트가 동일)에서만 리소스 접근을 허용합니다. CORS(Cross-Origin Resource Sharing)는 이러한 제한을 안전하게 우회할 수 있는 메커니즘을 제공합니다. 서버는 Access-Control-Allow-Origin 헤더를 통해 리소스에 접근할 수 있는 출처를 지정할 수 있으며, 프리플라이트 요청(OPTIONS 메서드)을 통해 실제 요청 전에 안전성을 확인할 수 있습니다. 복잡한 요청(Custom Headers, PUT/DELETE 등)의 경우 프리플라이트 요청이 자동으로 발생하며, 서버는 Access-Control-Allow-Methods, Access-Control-Allow-Headers 등의 헤더로 허용할 메서드와 헤더를 지정할 수 있습니다. 개발 환경에서는 프록시 서버를 통해 CORS 이슈를 우회할 수 있습니다.",
  },
  {
    question: "브라우저의 이벤트 루프와 태스크 큐에 대해 설명해주세요.",
    answer:
      "브라우저의 이벤트 루프는 JavaScript의 동시성 모델을 구현하는 메커니즘입니다. 콜 스택이 비어있을 때 태스크 큐에서 태스크를 가져와 실행합니다. 태스크 큐에는 매크로태스크(setTimeout, setInterval, 이벤트 콜백 등)와 마이크로태스크(Promise, process.nextTick 등)가 있으며, 마이크로태스크는 매크로태스크보다 우선순위가 높습니다. 각 매크로태스크 실행 후에는 모든 마이크로태스크가 처리되며, 이후 렌더링이 발생할 수 있습니다. 이러한 구조를 이해하는 것은 성능 최적화와 비동기 프로그래밍에 중요합니다.",
  },
  {
    question: "웹 성능 최적화 방법과 성능 측정 지표에 대해 설명해주세요.",
    answer:
      "웹 성능 최적화는 다양한 측면에서 접근할 수 있습니다. 리소스 최적화를 위해 이미지 압축, 코드 분할, 트리 쉐이킹, 미니파이케이션을 사용하고, 네트워크 최적화를 위해 CDN 활용, HTTP/2 적용, 브라우저 캐싱 설정을 합니다. 렌더링 최적화를 위해서는 레이지 로딩, 컴포넌트 메모이제이션, 가상 스크롤을 적용할 수 있습니다. 성능 측정 지표로는 Core Web Vitals가 중요한데, LCP(Largest Contentful Paint)는 주요 콘텐츠 로딩 시간, FID(First Input Delay)는 상호작용 응답 시간, CLS(Cumulative Layout Shift)는 레이아웃 안정성을 측정합니다. 이외에도 TTFB(Time to First Byte), FCP(First Contentful Paint) 등의 지표를 통해 성능을 종합적으로 평가하고 개선할 수 있습니다.",
  },
  {
    question: "웹소켓(WebSocket)과 HTTP의 차이점을 설명해주세요.",
    answer:
      "웹소켓은 클라이언트와 서버 간의 양방향 실시간 통신을 지원하는 프로토콜입니다. HTTP가 요청-응답 기반의 단방향 통신인 반면, 웹소켓은 한 번의 핸드셰이크로 연결을 수립한 후 양방향으로 데이터를 주고받을 수 있습니다. 이는 채팅, 실시간 게임, 주식 시세 등 실시간 데이터 전송이 필요한 애플리케이션에 적합합니다. 웹소켓은 연결이 유지되는 동안 지속적인 통신이 가능하여 HTTP polling이나 long polling에 비해 오버헤드가 적고 지연 시간이 짧습니다. 단, 연결 유지를 위한 서버 리소스가 필요하며, 프록시나 방화벽 설정에 주의가 필요합니다.",
  },
  {
    question: "브라우저 캐싱 전략과 Cache-Control 헤더에 대해 설명해주세요.",
    answer:
      "브라우저 캐싱은 웹 성능 최적화의 핵심 요소로, Cache-Control 헤더를 통해 세밀하게 제어할 수 있습니다. no-cache는 캐시는 하지만 사용 전 서버에 검증을 요청하고, no-store는 캐시를 완전히 비활성화하며, public은 공유 캐시에 저장을 허용하고, private은 브라우저에만 저장을 허용합니다. max-age는 캐시 유효 기간을, stale-while-revalidate는 캐시가 만료된 후에도 캐시된 콘텐츠를 제공하면서 백그라운드에서 갱신하는 전략을 제공합니다. 정적 자산은 긴 max-age와 함께 버전 관리나 해시를 사용하고, API 응답은 상황에 따라 적절한 캐시 전략을 선택해야 합니다.",
  },
  {
    question: "SEO 최적화를 위한 주요 기술과 방법들을 설명해주세요.",
    answer:
      "SEO 최적화를 위한 주요 기술과 방법으로는 1) 메타 태그 최적화(title, description, robots), 2) 시맨틱 HTML 구조 사용(header, nav, main, article 등), 3) 적절한 헤딩 구조(h1~h6), 4) 이미지 alt 속성 제공, 5) 모바일 친화적인 반응형 디자인, 6) 페이지 로딩 속도 최적화, 7) 올바른 URL 구조와 사이트맵 제공, 8) 구조화된 데이터(Schema.org) 마크업 적용, 9) Open Graph 태그 설정, 10) Core Web Vitals 최적화 등이 있습니다. Next.js의 경우 SSR/SSG를 통해 검색 엔진 크롤링을 용이하게 하고, next/head 컴포넌트로 메타 태그를 동적으로 관리할 수 있습니다.",
  },
  {
    question:
      "Core Web Vitals가 SEO에 미치는 영향과 최적화 방법을 설명해주세요.",
    answer:
      "Core Web Vitals는 Google의 페이지 경험 지표로, SEO 순위에 직접적인 영향을 미칩니다. 주요 지표로는 1) LCP(Largest Contentful Paint): 최대 콘텐츠 렌더링 시간(2.5초 이내 목표), 2) FID(First Input Delay): 최초 입력 지연 시간(100ms 이내 목표), 3) CLS(Cumulative Layout Shift): 누적 레이아웃 이동(0.1 이하 목표)이 있습니다. 최적화 방법으로는 이미지/폰트 최적화, 중요 CSS 인라인화, JavaScript 지연 로딩, 이미지 크기 사전 지정, 광고/임베드 요소 공간 예약 등이 있습니다. Lighthouse나 PageSpeed Insights를 통해 측정하고 개선할 수 있습니다.",
  },
  {
    question:
      "검색 엔진 최적화(SEO)를 위한 SSR과 CSR의 차이점과 선택 기준을 설명해주세요.",
    answer:
      "SSR은 서버에서 완전한 HTML을 생성하여 검색 엔진이 콘텐츠를 쉽게 크롤링할 수 있게 하며, 초기 로딩 성능이 우수합니다. CSR은 클라이언트에서 JavaScript로 콘텐츠를 렌더링하여 검색 엔진의 크롤링이 제한적일 수 있습니다. Next.js나 Nuxt.js는 페이지별로 SSR/SSG/CSR을 선택적으로 적용할 수 있어, 콘텐츠 특성에 따라 최적의 렌더링 방식을 선택할 수 있습니다. 정적 콘텐츠는 SSG, 동적이지만 SEO가 중요한 페이지는 SSR, 개인화된 대시보드 등은 CSR을 사용하는 것이 일반적입니다.",
  },
  {
    question: "하이드레이션(Hydration)이란 무엇이며, SSR에서 왜 중요한가요?",
    answer:
      "하이드레이션은 서버에서 렌더링된 정적 HTML에 JavaScript 동작을 부여하는 과정입니다. SSR에서 서버는 초기 HTML을 생성하여 클라이언트로 전송하는데, 이 HTML은 정적이며 상호작용이 불가능한 상태입니다. 클라이언트에서 React가 이 HTML을 대상으로 하이드레이션을 수행하면서 이벤트 리스너를 연결하고 상태를 초기화하여 동적인 웹 애플리케이션으로 전환됩니다. 하이드레이션이 중요한 이유는 다음과 같습니다. 첫째, 사용자는 JavaScript가 완전히 로드되기 전에도 콘텐츠를 볼 수 있어 더 나은 사용자 경험을 제공합니다. 둘째, SEO에 유리한 서버 사이드 렌더링의 이점을 유지하면서도 풍부한 상호작용이 가능한 애플리케이션을 구현할 수 있습니다. 셋째, 점진적인 JavaScript 로딩과 실행이 가능해져 전반적인 성능 개선에 도움이 됩니다. 하지만 하이드레이션 과정에서 주의해야 할 점들도 있습니다. 서버와 클라이언트의 렌더링 결과가 일치해야 하며(불일치 시 하이드레이션 오류 발생), 큰 번들 사이즈는 하이드레이션 시간을 늘릴 수 있습니다. 이를 해결하기 위해 Next.js나 React 18은 선택적 하이드레이션, 스트리밍 SSR 등의 기능을 제공합니다. 또한 최근에는 Partial Hydration, Islands Architecture 등 하이드레이션을 최적화하는 다양한 접근 방식이 등장하고 있습니다.",
  },
];

export default webQuestions;
